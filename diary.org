* 201301301752-LTI-PROJETO-TM
Objetivo: gerar $weights$ para reuso.

diff keepaway.sh.original keepaway.sh
23,24c23,24
< keeper_learn=0                   # should learning be turned on for keepers?
< #keeper_policy="learned"         # policy followed by keepers
---
> keeper_learn=1                   # should learning be turned on for keepers?
> keeper_policy="learned"          # policy followed by keepers
27c27
< keeper_policy="rand"
---
> #keeper_policy="rand"
44c44
< save_weights=0                    # should I save learned weights
---
> save_weights=1                    # should I save learned weights
63c63
< synch_mode=0                     # should I speed up with synchronous mode?
---
> synch_mode=1                     # should I speed up with synchronous mode?
66c66
< save_rcg_log=0                   # should I save game log to .rcg file?
---
> save_rcg_log=1                   # should I save game log to .rcg file?
* 201301301958-LTI-PROJETO-TM
Objetivo: testar reuso de $weights$

diff keepaway.sh.original keepaway.sh
21,22c21,22
< keeper_load=0                    # should I load previously learned weights?
< keeper_load_dir=                 # sub-directory of weight_dir where weights are stored
---
> keeper_load=1                    # should I load previously learned weights?
> keeper_load_dir=201301301752-LTI-PROJETO-TM                 # sub-directory of weight_dir where weights are stored
24c24
< #keeper_policy="learned"         # policy followed by keepers
---
> keeper_policy="learned"          # policy followed by keepers
27c27
< keeper_policy="rand"
---
> #keeper_policy="rand"
44c44
< save_weights=0                    # should I save learned weights
---
> save_weights=1                    # should I save learned weights
63c63
< synch_mode=0                     # should I speed up with synchronous mode?
---
> synch_mode=1                     # should I speed up with synchronous mode?
66c66
< save_rcg_log=0                   # should I save game log to .rcg file?
---
> save_rcg_log=1                   # should I save game log to .rcg file?
* 201301302106-LTI-PROJETO-TM
Objetivo: obter pesos muito bons


diff keepaway.sh.original keepaway.sh
22,24c22,24
< keeper_load_dir=                 # sub-directory of weight_dir where weights are stored
< keeper_learn=0                   # should learning be turned on for keepers?
< #keeper_policy="learned"         # policy followed by keepers
---
> keeper_load_dir=201301301752-LTI-PROJETO-TM                 # sub-directory of weight_dir where weights are stored
> keeper_learn=1                   # should learning be turned on for keepers?
> keeper_policy="learned"          # policy followed by keepers
27c27
< keeper_policy="rand"
---
> #keeper_policy="rand"
44c44
< save_weights=0                    # should I save learned weights
---
> save_weights=1                    # should I save learned weights
63c63
< synch_mode=0                     # should I speed up with synchronous mode?
---
> synch_mode=1                     # should I speed up with synchronous mode?
66c66
< save_rcg_log=0                   # should I save game log to .rcg file?
---
> save_rcg_log=1                   # should I save game log to .rcg file?
* 201302131649-LTI-PROJETO-TM
3v2.

Geração de pesos.

Testes da nova estrutura de treinamento.

Já com nova estrutura de estados, que foi feita para a transferência
de conhecimento.

* 201302141237-LTI-PROJETO-TM
Mais um 3v2 pra comparar o aprendizado antes e depois da modificação.
* 201302141632-LTI-PROJETO-TM
Mais um 3v2 pra comparar o aprendizado antes e depois da modificação.
* 201302142138-LTI-PROJETO-TM
4v3 na nova representação
* 201302150114-LTI-PROJETO-TM
4v3 reusando 201302141237-LTI-PROJETO-TM.
Atentando que somente 3 dos 4 jogadores abriram weights.
Inicialmente o desempenho é ruim (transf. negativa).

Possivelmente tentar posteriormente copiar k3-weights para k4-weights
(se eu não me engano, foi assim que o Fernandez'10 fez).

O HD ficou cheio.

Deletei os .cfg da pasta logs após o início do experimento.
* 201302151146-LTI-PROJETO-TM
4v3 reusando 201302141237-LTI-PROJETO-TM.
Copiado k3-weghts para k4-weights.
Isso traz como consequencia: o quarto jogador joga da mesma forma que
o terceiro.
Entretanto, não corrige a negligência à ação passK4.
* 201302161522-LTI-PROJETO-TM
O reuso realizado em 201302151146-LTI-PROJETO-TM não apresentou
resultados positivos.

Acredito que o problema do aprendizado está na negligência à ação
pass_k4, que inicialmente está desprovida de pesos.

Para corrigir isso, modifiquei o fonte de forma a clonar os pesos
aprendidos para a pass_k3 diretamente em pass_k4.

Dessa forma, no reuso, os jogadores valorizariam a ação pass_k4 tanto
quanto a ação pass_k3.

Com isso, espero corrigir o problema no aprendizado.

Experimento realizado: aprendizado 3v2, só que aprendendo os pesos
para a ação pass_k4.
* 201302162051-LTI-PROJETO-TM
4v3 reusando 201302161522-LTI-PROJETO-TM.

Como foram aprendidos os pesos para pass_k4, espero um desempenho de
aprendizado melhor do que o "puro".
